# AI DAST Scanner - Vulnerable Web App Environment Configuration
# Copy this file to .env and modify as needed:
#   cp .env.example .env
#
# ============================================================================
# PORT CONFIGURATION
# ============================================================================

# Vulnerable web application port
# Change this if port 8080 is already in use on your system
# The AI DAST scanner expects the target at http://localhost:APP_PORT
APP_PORT=8080

# ============================================================================
# FLASK CONFIGURATION (Optional)
# ============================================================================

# Flask environment: development or production
# - development: Enables verbose error messages and auto-reload
# - production: Optimized for production-like testing (RECOMMENDED)
FLASK_ENV=production

# Flask debug mode: 0=disabled, 1=enabled
# Recommended: disabled for production-like testing
FLASK_DEBUG=0

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================

# LLM provider to use: ollama, openrouter, openai
# Default: ollama (for backward compatibility)
LLM_PROVIDER=ollama

# ----------------------------------------------------------------------------
# Ollama Configuration (default provider)
# ----------------------------------------------------------------------------

# Ollama model to use (optional, auto-detected if not set)
# Can include provider prefix: ollama/llama3
OLLAMA_MODEL=

# Ollama server host URL
OLLAMA_HOST=http://localhost:11434

# Request timeout in seconds (default: 500 for complex AI reasoning)
OLLAMA_TIMEOUT=500

# Maximum retry attempts for failed requests
OLLAMA_MAX_RETRIES=3

# ----------------------------------------------------------------------------
# OpenRouter Configuration
# ----------------------------------------------------------------------------

# OpenRouter API key (required if LLM_PROVIDER=openrouter)
# Get your API key at https://openrouter.ai/keys
OPENROUTER_API_KEY=

# OpenRouter model to use
# Examples: anthropic/claude-3.5-sonnet, openai/gpt-4o, meta-llama/llama-3-70b-instruct
# Can include provider prefix: openrouter/anthropic/claude-3.5-sonnet
OPENROUTER_MODEL=

# ----------------------------------------------------------------------------
# OpenAI Configuration
# ----------------------------------------------------------------------------

# OpenAI API key (required if LLM_PROVIDER=openai)
# Get your API key at https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenAI model to use (default: gpt-4o)
# Can include provider prefix: openai/gpt-4o
OPENAI_MODEL=gpt-4o

# OpenAI API base URL (optional, for Azure OpenAI or compatible APIs)
# OPENAI_BASE_URL=

# ============================================================================
# SCANNER CONFIGURATION (Optional)
# ============================================================================

# Maximum response body size to include in prompts (characters)
# MAX_RESPONSE_BODY_SIZE=4000

# Maximum tokens in AI response
# MAX_RESPONSE_TOKENS=2048

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

